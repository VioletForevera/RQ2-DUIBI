CartPole持续学习指标报告
==================================================

1. 收敛速度 (Convergence Speed)
------------------------------
任务 1 (T1: short+no wind): 53 episodes
任务 2 (T2: short+wind): 72 episodes
任务 3 (T3: long+no wind): 86 episodes
任务 4 (T4: long+wind): 96 episodes
平均收敛速度: 76.8 episodes

2. 平均回报 (Average Reward)
------------------------------
任务 1 (T1: short+no wind): 128.81
任务 2 (T2: short+wind): 373.07
任务 3 (T3: long+no wind): 494.70
任务 4 (T4: long+wind): 500.00
跨任务平均奖励: 374.14

3. 灾难性遗忘 (Catastrophic Forgetting)
------------------------------
任务 1 在训练任务 2 后:
  训练前性能: 29.20
  训练后性能: 500.00
  性能变化: +470.80 (正向迁移)

任务 1 在训练任务 3 后:
  训练前性能: 29.20
  训练后性能: 500.00
  性能变化: +470.80 (正向迁移)

任务 2 在训练任务 3 后:
  训练前性能: 316.60
  训练后性能: 500.00
  性能变化: +183.40 (正向迁移)

任务 1 在训练任务 4 后:
  训练前性能: 29.20
  训练后性能: 500.00
  性能变化: +470.80 (正向迁移)

任务 2 在训练任务 4 后:
  训练前性能: 316.60
  训练后性能: 492.40
  性能变化: +175.80 (正向迁移)

任务 3 在训练任务 4 后:
  训练前性能: 500.00
  训练后性能: 500.00
  性能变化: +0.00 (正向迁移)

任务 2 在训练任务 1 后:
  训练前性能: 316.60
  训练后性能: 490.40
  性能变化: +173.80 (正向迁移)

任务 3 在训练任务 1 后:
  训练前性能: 500.00
  训练后性能: 489.00
  性能变化: -11.00 (灾难性遗忘)

任务 4 在训练任务 1 后:
  训练前性能: 500.00
  训练后性能: 492.40
  性能变化: -7.60 (灾难性遗忘)

4. 熵门控统计 (EGP)
------------------------------
任务 1 (T1: short+no wind): 触发次数=40, 暂停步数=440
任务 2 (T2: short+wind): 触发次数=40, 暂停步数=440
任务 3 (T3: long+no wind): 触发次数=40, 暂停步数=440
任务 4 (T4: long+wind): 触发次数=40, 暂停步数=440

5. 动态遗憾 (Dynamic Regret)
------------------------------
任务 1 (T1: short+no wind):
  平均动态遗憾: 371.19
  奖励曲线总变差(平滑度): 3329.00
  最终奖励EWMA: 342.03
任务 2 (T2: short+wind):
  平均动态遗憾: 126.93
  奖励曲线总变差(平滑度): 3230.00
  最终奖励EWMA: 310.47
任务 3 (T3: long+no wind):
  平均动态遗憾: 5.30
  奖励曲线总变差(平滑度): 106.00
  最终奖励EWMA: 322.84
任务 4 (T4: long+wind):
  平均动态遗憾: 0.00
  奖励曲线总变差(平滑度): 0.00
  最终奖励EWMA: 325.66

