CartPole持续学习指标报告
==================================================

1. 收敛速度 (Convergence Speed)
------------------------------
任务 1 (T1: short+no wind): 41 episodes
任务 2 (T2: short+wind): 54 episodes
任务 3 (T3: long+no wind): 66 episodes
任务 4 (T4: long+wind): 76 episodes
平均收敛速度: 59.2 episodes

2. 平均回报 (Average Reward)
------------------------------
任务 1 (T1: short+no wind): 176.35
任务 2 (T2: short+wind): 413.42
任务 3 (T3: long+no wind): 473.70
任务 4 (T4: long+wind): 484.09
跨任务平均奖励: 386.89

3. 灾难性遗忘 (Catastrophic Forgetting)
------------------------------
任务 1 在训练任务 2 后:
  训练前性能: 29.20
  训练后性能: 472.00
  性能变化: +442.80 (正向迁移)

任务 1 在训练任务 3 后:
  训练前性能: 29.20
  训练后性能: 479.60
  性能变化: +450.40 (正向迁移)

任务 2 在训练任务 3 后:
  训练前性能: 463.20
  训练后性能: 486.20
  性能变化: +23.00 (正向迁移)

任务 1 在训练任务 4 后:
  训练前性能: 29.20
  训练后性能: 483.20
  性能变化: +454.00 (正向迁移)

任务 2 在训练任务 4 后:
  训练前性能: 463.20
  训练后性能: 490.20
  性能变化: +27.00 (正向迁移)

任务 3 在训练任务 4 后:
  训练前性能: 480.80
  训练后性能: 490.60
  性能变化: +9.80 (正向迁移)

任务 2 在训练任务 1 后:
  训练前性能: 463.20
  训练后性能: 486.20
  性能变化: +23.00 (正向迁移)

任务 3 在训练任务 1 后:
  训练前性能: 480.80
  训练后性能: 484.80
  性能变化: +4.00 (正向迁移)

任务 4 在训练任务 1 后:
  训练前性能: 493.00
  训练后性能: 491.40
  性能变化: -1.60 (灾难性遗忘)

4. 熵门控统计 (EGP)
------------------------------
任务 1 (T1: short+no wind): 触发次数=42, 暂停步数=462
任务 2 (T2: short+wind): 触发次数=42, 暂停步数=462
任务 3 (T3: long+no wind): 触发次数=42, 暂停步数=462
任务 4 (T4: long+wind): 触发次数=42, 暂停步数=462

5. 动态遗憾 (Dynamic Regret)
------------------------------
任务 1 (T1: short+no wind):
  平均动态遗憾: 323.65
  奖励曲线总变差(平滑度): 3557.00
  最终奖励EWMA: 390.00
任务 2 (T2: short+wind):
  平均动态遗憾: 86.58
  奖励曲线总变差(平滑度): 1291.00
  最终奖励EWMA: 281.03
任务 3 (T3: long+no wind):
  平均动态遗憾: 26.30
  奖励曲线总变差(平滑度): 326.00
  最终奖励EWMA: 310.46
任务 4 (T4: long+wind):
  平均动态遗憾: 15.91
  奖励曲线总变差(平滑度): 350.00
  最终奖励EWMA: 333.56

